Graph-based Fuzz Testing for Deep Learning Inference Engines

基于图的深度学习推理机模糊测试

> 推理机是一组程序，用来控制、协调整个系统。
>
> 在一定的控制策略下，专家系统根据问题信息——用户和专家系统交流的信息，以及知识库中的知识执行对问题的求解。

## 摘要

随着深度学习系统的广泛使用，学术界和工业界开始关注其质量。

测试是质量保证的主要方法之一。

然而现有的测试技术侧重于DL模型的质量，但是对核心底层推理机的关注。

受模糊测试成功案例的启发，我们设计了一种基于图的模糊测试方法，以提高DL推理机的质量。

> 目的是测试DL推理机的质量。

这个方法自然地遵循了DL模型的图结构。

我们引入了一种基于图论的``新型算子覆盖标准``，并实现了六种不同的突变，以通过探索模型结构，参数的组合来产生多样化的DL模型。

蒙特卡洛树搜索（MCTS）被用来驱动DL模型生成，无需训练过程。

实验结果表明，MCTS在提高运算符级覆盖率和检测异常方面优于随机方法。

我们的方法在三类不希望出现的行为中发现了40多种不同的异常情况：模型转换失败、推理失败、输出比较失败。

突变策略有助于产生新的有效测试输入，平均而言，操作者级别的覆盖率提高了8.2%，捕获的异常情况增加了8.6个。

## Index Terms

深度学习推理机, 图论,
深度学习模型, Operator-Level Coverage, Monte Carlo Tree Search

## Introduction

深度学习（DL）是一种流行的方法，用于解决各个领域的硬计算问题，如图像分类[1]和语音识别[2]。

DL框架、数据集、模型、平台等的组合几乎不计其数[3]。

在硬件方面，平台是非常多样化的，从普通的处理器(例如，CPU、GPU和NPU）到FPGA、ASIC和外来的加速器，如模拟和混合信号处理器。

这些平台具有特定的硬件功能和约束，可以根据DL模型和场景来启用或者破坏推理。

在软件方面，一些DL应用程序调用的DL推理机通常用于优化各种DL模型并在上述设备上进行运行时加速推理，如NVIDIA TensorRT[4]、TensorFlow-Lite[5]和阿里巴巴MNN[6]。

因此，支持DL模型的DL推理机对于应用的质量非常重要。

据我们所知，目前仍然缺乏对DL推理机的系统测试方法。

模糊测试是一种广泛使用的自动化测试技术。

它生成随机数据作为输入，以检测软件中的崩溃、内存泄漏和其他故障[7]。

模糊测试已经被证明是DL系统质量保障的一个重要方向[8] [9]。

然而，现有的模糊测试技术在很大程度上依赖于手工设计的DL模型，通常会有扰动。比如说，层的增加、层的移除、数据的洗牌、噪声等，会对现有的模型或者数据进行扰动[10] [11] [12]。

与对DL模型的模糊测试不同的是，对DL推理机的模糊测试预计会通过探索模型结构、参数、权重的组合来生成多样化的DL模型。

这是很复杂的图结构数据。**自动和有效地生成这种复杂的图结构数据是非常具有挑战性的。**

在DL推理机的模糊测试中，第一个挑战就是生成多样化的DL模型，以触发一个给定DL推理机的不同的结构部分。

这些结构化部分包括模型结构转换、模型优化(例如，运算符融合），数据格式转换（例如，NCHW,
NHWC、NC4HW4[6]）、运算符实现、计算图形调度、数据移动、瓦片的层次结构，等等[13]。

 第二个挑战是如何捕捉每个测试的行为，从而使模糊测试能够很好地指导生成新的测试。

现有的神经覆盖率标准不能在这种测试场景中发挥作用，因为DL推理机的输入是DL模型。

需要一个新的标准来捕获DL推理机的行为，而不是DL模型。

很自然的设计测试方法的灵感来自于DL模型的图结构，对不同的DL模型进行分析。

本文设计了一种新型的基于图的模糊测试方法，通过将DL模型生成为数字图来测试DL推理机。

该方法的理念自然符合DL模型的图形结构。它缓解了生成大量不同的DL模型的问题。

由于DL模型不是一个简单的数字图，它们具有丰富的深度学习元素的特点。

因此，在DL模型生成的基础上，有四个模型级的突变，包括图边添加、图边移除、块节点添加、块节点移除，以及两个源级突变，包括张量形状突变和参数突变，以有效地生成更多样化的DL模型。

为了指导被测试的特定DL推理引擎进行更有效的模糊测试，应该捕获每个测试（DL模型）的动态行为。操作者级别的覆盖率覆盖率标准是由图论引入的，用于衡量测试引擎逻辑中被测试的部分，以衡量DL推理引擎的逻辑被测试集（若干DL模型）行使的的逻辑部分，基于运算符类型、结构（例如图论中的输入度、输出度和单边）、张量形状和参数）。

操作者的成功率和操作者级别的覆盖率被用作反馈给蒙特卡洛树搜索（MCTS）。MCTS用于解决搜索问题，以确定一个操作者在新模型中是否被选择，这样就可以选择最有希望的区块来生成随机DL模型。实验是在X86 CPU和ARM CPU上用**MNN**[6]设计和进行的。实验结果表明，我们的方法在检测DL推理引擎的异常方面是有效的，发现了40多种不同的异常，如崩溃、不一致、nan和inf bug。

此外，基于MCTS的搜索在提高运算符级别的覆盖率（多出6.7%）和检测异常（多出6.7%）方面比基于随机的搜索表现更好（多6.7%）和检测异常（多9.7%）。还有，该突变策略有助于产生多8.2%的运算符覆盖率平均多检测出8.6个例外情况。

我们在本文中的主要贡献有以下几点。
- 提出了一种新的基于图的DL推理机模糊测试技术，其中DL模型被定义为来自自然和有效基础的图。
- 引入了一个新的运算符级别的覆盖标准，以通过奖励-引导的方式加强模糊测试。
该指标可以用来估计DL推理机的逻辑数量。
- 一些基于图的模型级变异（图边增加、去除图边、增加块状节点。
和源级突变（张量形状突变、参数突变）被提出来以产生多样化的DL模型。
- 在一个工业推理引擎上进行了实验评估。
结果表明，操作者层面的覆盖率指导测试框架提高了
在检测异常方面的有效性。

更多关于基于图的模糊测试的细节和实验的更多细节可以在https://github.com/gbftdlie/

## 背景

A DL推理机的工作流程

DL推理机被DL应用调用，在带有推理硬件加速器的设备上加载和运行模型。

现有的推理机工作流程是类似的。

以MNN[6]（阿里巴巴公司开发的轻量级DL推理引擎）为例，如图1所示，推理工作流程大致可分为两个阶段。

1. 转换：转换那些训练框架的阶段模型（如TensorFlow（Lite）、Caffe和ONNX）转换成MNN模型，并通过运算符融合、运算符替换和布局调整来优化DL模型。此外，MNN模型可以被选择性量化。
2. 推理：装入MNN模型并进行推断的阶段。MNN的解释器由引擎和后端组成。前者负责加载MNN模型和调度计算图。后端包括内存分配和运算器在每个计算设备下的实现。



![image-20211125092852076](C:/Users/chen/AppData/Roaming/Typora/typora-user-images/image-20211125092852076.png)



B 现有测试技术的限制

事实证明，模糊测试在探索DL系统测试的输入空间方面是有效的。

模糊测试的一个重要部分是如何进行反馈。DeepXplore[11]引入了神经元覆盖率的概念，用于衡量一组DL系统的逻辑系统的逻辑部分，根据一组测试输入所激活的的神经元数量（即输出值高于阈值）。

在DeepXplore的启发下，一些不同的覆盖率标准已经被应用于DL测试，如TensorFuzz[10]、Deeptest[14]和Deepgauge[15]. 这些测试技术专注于测试特定DL模型的质量。

然而，在DL推理机测试中，当输入模型被改变时，覆盖率作为反馈将是无效的。

模糊测试的另一个重要部分是通过对给定的输入集进行变异来生成测试。
DeepMutation[12］提出了一套变异操作符，包括通过干扰改变权重、偏置和输入，交换一个层内的神经元、增加或删除一个输入和输出维度相等的层，如批量归一化等。
这种方法对单一模型进行变异，以模拟错误情况。基于
TensorFuzz是另一个基于DL模型的输入数据变异的模糊测试生成工具。这些方法也可以
有效保证特定DL模型的质量。但是它们不能生成大量的多样化模型来测试推理引擎。
测试推理引擎，也就是说，尽管有大量的输入，但给定的模型没有变化或变化很小
因此，它们不太可能检测到错误的行为并触发DL推理机的不同部分逻辑。

> 两个局限：
>
> 覆盖率的没用
>
> 模型变化很小

总的来说，现有的测试技术集中在DL模型的质量上，但是缺乏对DL推理机测试的关注。

操作符（模型）的多样化组合比起特定的/单一的模型，更有能力触发DL推理引擎的问题。

单一模型所引发的问题是有限的。我们需要通过组合运算符来生成大量的模型作为DL推理引擎的测试输入。



## 方法

在本节中，我们提供了基于图的模糊测试的详细技术描述，用于DL推理引擎。

A 定义

图

随机网络的生成涉及以下定义：图、子图、块、块语料库、突变动作。

图：图论为研究和解释神经网络拓扑结构提供了一个很好的框架[16]。

神经网络可以用图G=（V，E）来表示。
V是一组运算符（例如Conv2d、Relu和Softmax）。

> 神经网络

E ⊆ { (x, y)|(x, y) ∈ V2 并且 x != y }

是一个有向边的集合

是一组有序的不同运算符对（例如，x和y）。

在神经网络中，边是数据流。



子图

从上面的介绍中，一些指定的
DL模型的结构将被特别处理（例如。
操作符融合和替换[17] [18]，以运行更快的
推理）。这些指定的结构有很低的概率
结构可以随机生成的概率很低。因此，子图被
应用于块，直接定义这些指定的结构
在测试中。形式上，

![image-20211125094214549](C:/Users/chen/AppData/Roaming/Typora/typora-user-images/image-20211125094214549.png)



块。在本文中，神经网络的子图或运算符被定义为
在本文中定义为块。一个网络是由
操作符和子图组成，如图2所示。



**块语料库。**一个块语料库包含要选择的区块和它们的属性，包括block name、允许的in-degree和out-degree的范围、块的内边。

当区块是一个子图时，内边是必须要有的的，否则可以是空的。
为了构建块语料库，测试人员首先需要确认要测试的运算符和子图的类型，并
然后将它们的上述属性填入块语料库。



突变行动。让I1，I2，. . ，In是一连串的突变测试集，其中Ik是由第k个突变动作产生的
MA(bsk, msk)。bsk和msk分别是第k个突变动作中的区块选择和突变运算符选择。
分别是第k个突变动作中的区块选择和突变算子选择。这两个动作的一个元组构成一个完整的动作
MA(bs, ms)。



##  代码覆盖率标准

传统的代码覆盖率标准在DL测试中是无效的。正如第II.B节所讨论的，最近提出的神经元覆盖率标准仍然是无效的，因为DL的推理引擎
测试涉及不同的模型。我们提出了一个新的操作者级别的标准，以捕捉由操作者组合的模型的差异。
的差异，从而提供反馈来指导拟议的基于图的模糊测试，以产生多样化的模型。如
在III-A中定义，我们使用模型结构、输入张量
形状、参数来描述DL模型中操作者的行为。
DL模型。正如III-A中所定义的，我们使用输入度
(输入数据流的数量)、输出数据流(输出数据流的数量)
输出数据流的数量），输入张量形状（NHWC,
等）和运算符的参数（例如，Conv2d的扩张）来描述DL中运算符的行为。
来描述DL模型中操作者的行为。
给定一个块状语料库BC和一个测试集I，运算符级别的
覆盖标准定义如下。



## 框架

如图4所示

![image-20211125213652766](C:/Users/chen/AppData/Roaming/Typora/typora-user-images/image-20211125213652766.png)

基于图的模糊测试框架由块选择器、覆盖率准则、输入变异器和变异选择器组成。

**对于每次迭代，基于MCTS的块选择器从块语料库中选择一组块b。**

变异选择器选择一个或者多个变异，以确定变异规则m。









## 算法

在FuzzWorkflow的程序中。
输入是区块语料库（BC）、突变（M）、终止条件（tc0），即新输入的目标数量。



第2行的
第2行的while循环迭代直到达到tc0。在第3行，由区块选择器选择区块。在第4行中，突变选择器
突变选择器选择突变和它们的参数。在
第5行，输入突变通过块和突变生成测试集Ik。
和突变。在第6行，计算Ik的运算符级别的覆盖率
被计算出来。在第7行，检查coveragek是否
产生额外的覆盖率。在第8行，进行MCTS模拟
进行。在第9行，当前的测试集，结果和当前的
操作员级别的覆盖率被更新。在第10行，MCTS反向
传播更新推理的结果，以更新
与从子节点C到根节点R的路径上的节点相关的值
C到根节点R。







在InputMutation的过程中，输入是选定的区块
bk，选定的模型级变异模型mk和源级变异源mk。在第16行，从选定的区块bk和模型突变中生成图形。
从选定的块bk和模型突变中生成图。在第17行。每个区块的输入形状和参数是由
图和数据突变生成。在第18行，根据图形和参数
图形和参数，生成测试集Ik。





在BlockChooser的程序中，输入是MCTS树的根节点R（根节点没有设置运算符），终止条件tc1是MCTS可以向下搜索的最大级别，终止条件tc2是一个节点可以探索的最大次数。
终止条件tc1是MCTS可以向下搜索的最大级别，终止条件tc2是一个节点可以被探索的最大次数。在第21行，为InputMutation选择块。在第22行，进行MCTS选择
进行。返回一个叶子节点L。在第23行，应用MCTS扩展来创建叶节点L的一个新的子节点C。
子节点C可以是最低覆盖率的算子或包含它的子图。
子节点C可以是最低的覆盖算子或包含它的子图，并且在之前的路径中没有被选择。
在第24-25行中，C的索引和沿路径的块从
子节点C到根节点R的路径的索引被返回。



模糊测试过程维护了一个包含区块及其属性的区块语料库，包括区块名称、允许的in-degree和out-degree范围、区块的内部边缘。



当一个区块是一个子图时，其区块名称被定义为子图中的运算符序列（即图5(a)中的区块Conv2d+Relu+Pow+Concat），其内边是必须的。内边的邻接列表中的每个元素都是一对源和目的运算符索引。以
算子Conv2d和两个子图（如图5所示）为例，Conv2d正好有一个输入，而两个子图
分别有两个。这两个子图的允许出度范围由测试框架设定，如{0,1,2}。

两个子图的]内边分别是{（0，1），（1，3），（2，3）}和{（0，2），（1，2），{2,3},{2,3}。







# 块选择器

块选择器是为DL模型的生成而设计的，以提高运算符级别的覆盖率并抑制重复的异常。随机选择算子来建立DL模型的测试中，会发现大量的重复异常。
在块选择器中，蒙特卡洛树搜索（MCTS）被用来搜索DL推理机的输入域，这样就可以在块选择器中选择最有希望的块来生成随机的DL模型。树的每个节点代表块语料库中的一个算子。MCTS动态地
适应最有希望的搜索区域，在那里好的组合可能会找到更多的例外。图6所示的MCTS，可分为以下四个步骤

1. 选择：

   从根节点R开始，根据它们的潜力依次选择子节点，直到到达叶节点L。

   每个子节点的潜力是通过以下方式计算的
   使用UCT（应用于树的置信度上限）[19] [20].

   UCT定义为：

   ![image-20211125214345911](C:/Users/chen/AppData/Roaming/Typora/typora-user-images/image-20211125214345911.png)

v指的是节点的成功次数，n是节点的访问次数，N是节点的父级访问次数。

e是一个超参数，决定探索与开发的权衡。搜索树的最大级别
的最大层数被设定为终端条件1
(tc1)。

2. 扩张。除非L是具有最高潜力的终端节点，否则创建一个具有最低覆盖率的子节点（运算符）C，并且运算符C不在路径中。我们挑选一个包含运算符C的运算符或子图。
3. 仿真。使用树的当前路径中的块生成随机的DL模型，直到达到一个终端条件
   条件，然后对模型进行推理。一个MCTS节点可以探索的最大次数
   一个MCTS节点可以被探索的最大次数被设定为终端条件2
   (tc2)。
4. 反向传播。将推理的结果向后传播，以更新路径上的节点的相关值
   含有每层中最高值的节点的路径将是测试中的最优策略。
   集。



## 设计实验的过程

块语料库

本实验的块语料库包括53个块，50个运算符和3个子图

1. 50个TensorFlow运算符，MNN支持

   Add, Argmax, Avgpooling, Batchtospacend,
   Biasadd, Cast, Ceil, Concat, Conv2d, Cropandresize, Deconv2d, Depthwise, Exp, Expanddims, Fill, Fusedbatchnorm,
   GatherV2, Greater, Lrn, Maximum, Maxpooling, Minimum,
   Mul, Realdiv, Reducemax, Reducemean, Reduceprod, Reducesum, Relu, Relu6, Reshape, Resizebilinear, Resizenearestneighbor, Rsqrt, Selu, Shape, Sigmoid, Resize, Slice, Softmax,
   Spacetobatchnd, Sqrt, Square, Squeeze, Stridedslice, Sub,
   Tanh, Tile, TopKV2, Transpose.

   MNN是一个轻量级的深度神经网络推理引擎，在端侧加载深度神经网络模型进行推理预测。目前，MNN已经在阿里巴巴的手机淘宝、手机天猫、优酷等20多个App中使用，覆盖直播、短视频、搜索推荐、商品图像搜索、互动营销、权益发放、安全风控等场景。此外，IoT等场景下也有若干应用。

   轻量级、通用性、高性能、易用性

   

2.  子图。子图1（图7(a)）是指SSD中多个特征图的串联[23]。子图2（图。
   7(b)）的灵感来自于TensorFlow图形优化中的运算符融合和算术优化器
   在TensorFlow图形优化中。子图3（图7(c)）受到MNN中运算器融合的启发。
   受到MNN中算子融合的启发。我们将输出的范围度设置为{0, 1, 2, 3, 4, 5}。
