[toc]

# 背景与介绍

## 视觉问答

[VQA_Demo](../util/0. VQA_Demo)

### 视觉问答是什么

视觉问答Visual Question Answer (VQA) 是对视觉图像的自然语言问答，作为视觉理解 (Visual Understanding) 的一个研究方向，连接着视觉和语言，模型需要在理解图像的基础上，根据具体的问题然后做出回答。

下面是一个视觉问答的小例子（源自知乎）：

想象一个系统，它可以回答这些问题：

- 图像中有什么？
- 有人类吗?
- 什么运动正在进行？
- 谁在踢球?
- 图像中有多少球员？
- 参赛者有哪些人?
- 在下雨吗?

![img](https://pic4.zhimg.com/80/v2-bcae40fa7dc4a586efeec0ad5504736f_720w.jpg)

作为人类，我们可以很轻松执行这项任务，但是研究具有这种功能的系统似乎有些困难。

然而，随着深度学习（DL）的出现，我们目睹了视觉问答（VQA）方面的巨大研究进展，使得能够回答这些问题的系统正在出现，并带来很有希望的成果。

### 视觉问答的简单原理

当被问到：

**巴黎有几座桥梁？**

视觉问答中的**NLP问答系统**通常会：

- 分类或输入问题：这是一个“多少”问题，因此答复必须是一个数字。
- 提取对象以计数：桥梁。
- 提取必须执行计数的上下文：在这种情况下，巴黎市。

这是基于普通的NLP问答系统而言的，对于VQA来说：

- 搜索和推理部分必须在图像内容中进行

过程如下：

1. 先对图像image和问题question提取特征

2. 联合这些特征做一些多模态融合（如element-wise product, MCB，MFB），attention，知识补充等处理

   简单的多模态的特征融合方法有**element-wise product (multiply) / element-wise sum,  concatenation**，增加额外层的 **concatenation + FCL/CNN/LSTM** 等等

   ![img](https://upload-images.jianshu.io/upload_images/11731515-ca5ba41a1be776d1.png?imageMogr2/auto-orient/strip|imageView2/2/w/743/format/webp)

3. 经过分类器输出answer

对于图像image：使用VGG，Resnet，……

对于问题question：使用LSTM, GRU, ……

### 准确率

![img](https://upload-images.jianshu.io/upload_images/11731515-4756eaf57425b688.png?imageMogr2/auto-orient/strip|imageView2/2/w/722/format/webp)

下表列出一些模型的准确率：

![img](https://upload-images.jianshu.io/upload_images/11731515-572fabf2c7c4f1b5.png?imageMogr2/auto-orient/strip|imageView2/2/w/725/format/webp)

### 总结

作为需要视觉理解与推理能力的，介于Vision与NLP间的视觉问答VQA，是一个有趣而又充满挑战的问题。它的进步不仅依赖于计算机视觉的发展和自然语言处理的能力，还需要对图像的理解——视觉基础能力，如识别，检测等，同时学习到知识与推理的能力。然而，这条路还有很长的距离要走。

在这里我们得到一个关键的点：现有的算法总是可以从更多的训练数据中受益匪浅。

因此，自动化数据扩充是一项很关键的技术。数据对模型来说是燃料。

> 参考文献：
>
> *VQA: Visual Question Answering*
>
> *Introduction to Visual Question Answering: Datasets, Approaches and Evaluation*
>
> *Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering*

## 视觉问答的数据增强

### 数据增强是什么？

数据增强也叫数据扩增，意思是在**不实质性的增加数据**的情况下，让**有限的数据产生等价于更多数据的价值**。

数据扩增的目的就是使得训练数据尽可能的接近测试数据，从而提高预测精度。另外数据扩增可以迫使网络学习到更鲁棒性的特征，从而使模型拥有更强的泛化能力。

### 常规图像数据增强方式

一般的数据增强方式有两种：

- 图像内容变换（data warping）

  包括几何、颜色变换，随机擦除，对抗训练，风格

  ![深度学习中的数据增强方法都有哪些？](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zdGF0aWMwMDEuaW5mb3EuY24vcmVzb3VyY2UvaW1hZ2UvNTkvMTYvNTk4OGMyNmE0YzcwODYzZjdmNTFkOGM2YTAyMzEwMTYuanBn?x-oss-process=image/format,png)

- 迁移图像采样（oversampling）

  训练的时候对少的一类图像进行重复选择

### VQA增强工作的问题

对于VQA的数据增强目前也没有相关工作，现有的基于图像的增强方案（如旋转和翻转）都不能直接应用于VQA，这是因为增强的同时还需要维持语义的正确性。

一个与方向相关的Question-Answer对，如果相关的图像被旋转或翻转，对于问题的回答可能不是真的。

例如，当问到电脑的位置是什么时，汽车是在垃圾桶的左边还是右边？使用一般方法进行数据增强之后结果可能是相反的答案。随机抹去与问题相关的图像，就会弄错物体的数量。

这样的转换是不可用的。

以前的工作基于图像内容和给定答案生成合理的问题，即视觉问题生成（VQG）。

VQG，Visual Question Generation，给定一张图片，来生成一个流畅且切合上下文主题的问句。

![img](https://pic3.zhimg.com/80/v2-1792b252cfb003d92c1e7728b1bc11aa_720w.jpg)

然而，相当一部分生成的问题要么有语法错误，要么措辞怪异。

此外，他们从同一目标数据集中的问题和图像中学习，因此生成的数据与原始数据的分布相同。

由于训练数据和测试数据通常不具有相同的分布，生成的数据不能帮助缓解过度拟合的问题。

### VQA数据增强

本文中，我们没有直接操作图像和问题，而是使用生成的图像和问题的对抗性例子作为作为增强的数据。

增强后的例子不会改变图像和问题中的视觉属性以及问题的语义。画面、问题、答案的正确性仍然保持。

### 总结

为了使VQA的模型更加细化精准，我们需要基于现有的画面、问题、答案进行数据扩增。

但是无论是单独对图像进行变换还是对问题与答案进行变换都不能达到我们想要的要求。

因为，在本篇论文中，我们决定使用图像和问题的对抗性例子作为作为增强的数据。

关于对抗性例子的生成，将在[下一节](# 对抗性测试生成)中讲到。

> 参考文献：
>
> *Generating diverse questions using variational autoencoders*
>
> *Visual question generation as dual task of visual question answering*

## 对抗性攻击

> adverserial attack

[FGSM-Keras](../util/LOG.md)

### 什么是对抗攻击

对输入样本故意添加一些人无法察觉的细微的干扰，导致模型以高置信度给出一个错误的输出。

以下面的图片作为直观解释：

对抗攻击就是使得DNN误判的同时，使得图片的改变尽可能少。

### 对抗攻击方法

有以下方法：

1. 像素修改

   可以针对一张已经有正确分类的image，对其进行细微的像素修改，可以在DNN下被错分为其他label。(图片来自知乎)

   ![img](https://pic4.zhimg.com/80/v2-ed60089ae25c81ba2677ec34ffa2a47f_720w.jpg)

   样本x的label为熊猫，在对x添加部分干扰后，在人眼中仍然分为熊猫，但对深度模型，却将其错分为长臂猿，且给出了高达99.3%的置信度

2. 像素攻击

   改动图片上的一个像素，就能让神经网络认错图，甚至还可以诱导它返回特定的结果。(图片来自知乎)

   ![img](https://pic2.zhimg.com/80/v2-59a3afcc069df94927ffe1efd62822e9_720w.jpg)

   改动图片上的一个像素，就能让神经网络认错图，甚至还可以诱导它返回特定的结果

   比如说上图中把船认成车。

3. 无意义的image

   同样，根据DNN，很容易产生一张在人眼下毫无意义的image，但是在DNN中能够获得高confidence的label（图片来自知乎）

   ![img](https://pic1.zhimg.com/80/v2-0390bba1f2c35220c8b099b8ab0f4ebc_720w.jpg)

   两种EA算法生成的样本，这些样本人类完全无法识别，但深度学习模型会以高置信度对它们进行分类，例如将噪声识别为狮子。

### 对抗性攻击的作用

DNN在很多方面已经展示出比人类要好的水平,比如image classification,machine translation等等。

DNN的可攻击性，导致了DNN在一些重要领域之内无法大规模部署，极大的限制了DNN的发展。

对对抗攻击有了比较深入的理解之后,才能对对抗防御有比较深入的理解。

对于VQA而言，对抗攻击形成的数据扩增可以对模型进行优化。

### 总结





