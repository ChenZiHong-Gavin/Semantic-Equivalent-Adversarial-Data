[toc]

# 背景与介绍

## 视觉问答

[VQA_Demo](../util/0. VQA_Demo)

### 视觉问答是什么

视觉问答Visual Question Answer (VQA) 是对视觉图像的自然语言问答，作为视觉理解 (Visual Understanding) 的一个研究方向，连接着视觉和语言，模型需要在理解图像的基础上，根据具体的问题然后做出回答。

下面是一个视觉问答的小例子（源自知乎）：

想象一个系统，它可以回答这些问题：

- 图像中有什么？
- 有人类吗?
- 什么运动正在进行？
- 谁在踢球?
- 图像中有多少球员？
- 参赛者有哪些人?
- 在下雨吗?

![img](https://pic4.zhimg.com/80/v2-bcae40fa7dc4a586efeec0ad5504736f_720w.jpg)

作为人类，我们可以很轻松执行这项任务，但是研究具有这种功能的系统似乎有些困难。

然而，随着深度学习（DL）的出现，我们目睹了视觉问答（VQA）方面的巨大研究进展，使得能够回答这些问题的系统正在出现，并带来很有希望的成果。

### 视觉问答的简单原理

当被问到：

**巴黎有几座桥梁？**

视觉问答中的**NLP问答系统**通常会：

- 分类或输入问题：这是一个“多少”问题，因此答复必须是一个数字。
- 提取对象以计数：桥梁。
- 提取必须执行计数的上下文：在这种情况下，巴黎市。

这是基于普通的NLP问答系统而言的，对于VQA来说：

- 搜索和推理部分必须在图像内容中进行

过程如下：

1. 先对图像image和问题question提取特征

2. 联合这些特征做一些多模态融合（如element-wise product, MCB，MFB），attention，知识补充等处理

   简单的多模态的特征融合方法有**element-wise product (multiply) / element-wise sum,  concatenation**，增加额外层的 **concatenation + FCL/CNN/LSTM** 等等

   ![img](https://upload-images.jianshu.io/upload_images/11731515-ca5ba41a1be776d1.png?imageMogr2/auto-orient/strip|imageView2/2/w/743/format/webp)

3. 经过分类器输出answer

对于图像image：使用VGG，Resnet，……

对于问题question：使用LSTM, GRU, ……

### 准确率

![img](https://upload-images.jianshu.io/upload_images/11731515-4756eaf57425b688.png?imageMogr2/auto-orient/strip|imageView2/2/w/722/format/webp)

下表列出一些模型的准确率：

![img](https://upload-images.jianshu.io/upload_images/11731515-572fabf2c7c4f1b5.png?imageMogr2/auto-orient/strip|imageView2/2/w/725/format/webp)

### 总结

作为需要视觉理解与推理能力的，介于Vision与NLP间的视觉问答VQA，是一个有趣而又充满挑战的问题。它的进步不仅依赖于计算机视觉的发展和自然语言处理的能力，还需要对图像的理解——视觉基础能力，如识别，检测等，同时学习到知识与推理的能力。然而，这条路还有很长的距离要走。

在这里我们得到一个关键的点：现有的算法总是可以从更多的训练数据中受益匪浅。

因此，自动化数据扩充是一项很关键的技术。数据对模型来说是燃料。

> 参考文献：
>
> *VQA: Visual Question Answering*
>
> *Introduction to Visual Question Answering: Datasets, Approaches and Evaluation*
>
> *Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering*

## 视觉问答的数据增强

### 数据增强是什么？

数据增强也叫数据扩增，意思是在**不实质性的增加数据**的情况下，让**有限的数据产生等价于更多数据的价值**。

数据扩增的目的就是使得训练数据尽可能的接近测试数据，从而提高预测精度。另外数据扩增可以迫使网络学习到更鲁棒性的特征，从而使模型拥有更强的泛化能力。

### 常规图像数据增强方式

一般的数据增强方式有两种：

- 图像内容变换（data warping）

  包括几何、颜色变换，随机擦除，对抗训练，风格

  ![深度学习中的数据增强方法都有哪些？](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zdGF0aWMwMDEuaW5mb3EuY24vcmVzb3VyY2UvaW1hZ2UvNTkvMTYvNTk4OGMyNmE0YzcwODYzZjdmNTFkOGM2YTAyMzEwMTYuanBn?x-oss-process=image/format,png)

- 迁移图像采样（oversampling）

  训练的时候对少的一类图像进行重复选择

### VQA增强工作的问题

对于VQA的数据增强目前也没有相关工作，现有的基于图像的增强方案（如旋转和翻转）都不能直接应用于VQA，这是因为增强的同时还需要维持语义的正确性。

一个与方向相关的Question-Answer对，如果相关的图像被旋转或翻转，对于问题的回答可能不是真的。

例如，当问到电脑的位置是什么时，汽车是在垃圾桶的左边还是右边？使用一般方法进行数据增强之后结果可能是相反的答案。随机抹去与问题相关的图像，就会弄错物体的数量。

这样的转换是不可用的。

以前的工作基于图像内容和给定答案生成合理的问题，即视觉问题生成（VQG）。

VQG，Visual Question Generation，给定一张图片，来生成一个流畅且切合上下文主题的问句。

![img](https://pic3.zhimg.com/80/v2-1792b252cfb003d92c1e7728b1bc11aa_720w.jpg)

然而，相当一部分生成的问题要么有语法错误，要么措辞怪异。

此外，他们从同一目标数据集中的问题和图像中学习，因此生成的数据与原始数据的分布相同。

由于训练数据和测试数据通常不具有相同的分布，生成的数据不能帮助缓解过度拟合的问题。

### VQA数据增强

本文中，我们没有直接操作图像和问题，而是使用生成的图像和问题的对抗性例子作为作为增强的数据。

增强后的例子不会改变图像和问题中的视觉属性以及问题的语义。画面、问题、答案的正确性仍然保持。

### 总结

为了使VQA的模型更加细化精准，我们需要基于现有的画面、问题、答案进行数据扩增。

但是无论是单独对图像进行变换还是对问题与答案进行变换都不能达到我们想要的要求。

因为，在本篇论文中，我们决定使用图像和问题的对抗性例子作为作为增强的数据。

关于对抗性例子的生成，将在[下一节](# 对抗性测试生成)中讲到。

> 参考文献：
>
> *Generating diverse questions using variational autoencoders*
>
> *Visual question generation as dual task of visual question answering*

## 对抗性测试生成



